{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNFeatureExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HMrzOYUp309Jz07yoa34gSYb6_g_8AqP",
      "authorship_tag": "ABX9TyM5cYdTLAEa1fAHD0RLyD+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omk42/Pattern-Mining/blob/master/CNNFeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP2KLpl_APgu",
        "colab_type": "text"
      },
      "source": [
        "**Installations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ1QfLwY_38O",
        "colab_type": "text"
      },
      "source": [
        "Caffe GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49UAoN5eSurB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install caffe-cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xP-3oCDAE8o",
        "colab_type": "text"
      },
      "source": [
        "Caffe CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmSLbbGETG4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install caffe-cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JW_Yg7dAW-f",
        "colab_type": "text"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWrwmw28Aals",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from pathlib import Path\n",
        "from skimage.util.shape import view_as_windows\n",
        "from skimage.transform import resize\n",
        "import scipy.io as sio\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gIWDwVXCRse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import caffe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1cZxpuNAd_d",
        "colab_type": "text"
      },
      "source": [
        "**Configurations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pq8SBn2Z9SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/content/drive/My Drive/MDPM/'\n",
        "\n",
        "conf_dataset = 'shoes_trim'\n",
        "conf_imgDir = ROOT + 'data/' + conf_dataset\n",
        "conf_numClasses = 1\n",
        "conf_numSamples = 100\n",
        "\n",
        "# conf_patchSize = 128\n",
        "# conf_patchSizeL2 = 160\n",
        "# conf_patchSizeL3 = 192\n",
        "conf_stepSize = 24\n",
        "conf_patchSize = 48\n",
        "\n",
        "# conf_caffe_def = ROOT + \"cnn/deploy1_fc6.prototxt\"\n",
        "conf_caffe_def_fc7 = ROOT + \"cnn/deploy1_fc7.prototxt\"\n",
        "conf_caffe_model = ROOT + \"cnn/bvlc_reference_caffenet.caffemodel\"\n",
        "\n",
        "conf_numTopActivation = 20\n",
        "conf_supp = 0.01\n",
        "conf_minLength = 3\n",
        "conf_maxLength = 6\n",
        "conf_confid = 30\n",
        "\n",
        "CROPPED_DIM = 227\n",
        "IMAGE_DIM = 256\n",
        "\n",
        "conf_output_dir = ROOT+ 'output/' + conf_dataset + '_fc7'\n",
        "conf_image_mean = conf_output_dir + '/dataset_mean.npy'\n",
        "\n",
        "\n",
        "# conf_cnnFeatures = ROOT+'output/' + conf_dataset + '/cnnFeatures2.npy'\n",
        "# conf_imageDict = ROOT + 'output/' + conf_dataset + '/imageDict.pkl'\n",
        "# conf_indexImg = ROOT + 'output/' + conf_dataset + '/indexImg.pkl'\n",
        "\n",
        "conf_cnnFeatures = conf_output_dir + '/cnnFeatures.npy'\n",
        "conf_imageDict = conf_output_dir + '/imageDict.pkl'\n",
        "conf_indexImg = conf_output_dir + '/indexImg.pkl'\n",
        "# conf_imageDict_new = conf_output_dir + '/imageDict5.pkl'\n",
        "# conf_indexImg_new = conf_output_dir + '/indexImg5.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkVdOvyyHGDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_MEAN = np.load(conf_image_mean)\n",
        "labels = [x for x in Path(conf_imgDir).iterdir()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSxN53lReVVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_caffe():\n",
        "  caffe.set_mode_cpu()\n",
        "  # net = caffe.Net(conf_caffe_def, conf_caffe_model, caffe.TEST)\n",
        "  net = caffe.Net(conf_caffe_def_fc7, conf_caffe_model, caffe.TEST)  \n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPB4wHzx-vj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caffe_net_forward (patch, net):\n",
        "  #caffe.set_device(0)\n",
        "  #caffe.set_mode_gpu()\n",
        "  transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
        "  transformer.set_mean('data', IMAGE_MEAN)\n",
        "  transformer.set_transpose('data', (2,0,1))\n",
        "  transformer.set_channel_swap('data', (2,1,0))\n",
        "  #transformer.set_raw_scale('data', 255.0)\n",
        "  net.blobs['data'].reshape(1,3,CROPPED_DIM, CROPPED_DIM)\n",
        "  net.blobs['data'].data[...] = transformer.preprocess('data', patch)\n",
        "  #print (net.blobs['data'].data.shape, net.blobs['data'].data)\n",
        "  #test= net.blobs['data'].data[0]\n",
        "  #debug_img((test.transpose(1,2,0)+256)/2, \"Transformed patch\" + str(np.all(test<256)))\n",
        "  #debug_img(transformer.deprocess('data',net.blobs['data'].data[0]), \"DeTransformed patch\"+ str(np.all(transformer.deprocess('data',net.blobs['data'].data[0])<256)))\n",
        "  #return \n",
        "  out = net.forward()\n",
        "  # print (\"Shape of output \", out['fc6'].shape)\n",
        "  return out['fc7']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtBuoK9ZckrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnnFeaExtraction(classId, patchSize):\n",
        "  label = labels[classId-1]  \n",
        "  #print (\"Shape of IMAGE MEAN is \", IMAGE_MEAN.shape)\n",
        "  image_dict = dict()\n",
        "  indexImage = list()\n",
        "  net = setup_caffe()\n",
        "\n",
        "  # with open(conf_imageDict, 'rb') as imageDictFile, open(conf_indexImg, 'rb') as indexImgFile:\n",
        "  #   # imageDictFile.seek(0)\n",
        "  #   # indexImgFile.seek(0)\n",
        "  #   image_dict = pickle.load(imageDictFile)\n",
        "  #   print (\"Image Dict is \", len(image_dict))\n",
        "  #   indexImage = pickle.load(indexImgFile) \n",
        "  #   print (\"Index Img is \", len(indexImage))\n",
        "\n",
        "  for imageID, im_path in enumerate(label.iterdir()):\n",
        "    if imageID in image_dict:\n",
        "      if image_dict[imageID] != im_path:\n",
        "        print (image_dict[imageID], im_path)\n",
        "      assert (image_dict[imageID] == im_path)\n",
        "      continue\n",
        "    print (\"Finished images=  \", imageID) \n",
        "    # if imageID >= 4000:\n",
        "    #   break\n",
        "    image_dict[imageID] = im_path\n",
        "    \n",
        "    patches = sample_images(im_path, patchSize)\n",
        "    #print(\"Shape of patches is \", patches.shape)\n",
        "    # num_patches = patches.shape[0]*patches.shape[1] \n",
        "    # indexImage += [imageID for _ in range(num_patches)]\n",
        "\n",
        "    # images = np.zeros((CROPPED_DIM, CROPPED_DIM, 3, num_patches), dtype=float)\n",
        "    # cnnFea = np.zeros((4096, num_patches))\n",
        "    #print (\"Shape of images is \", images.shape)\n",
        "    #print (\"Shape of cnnFea is \", cnnFea.shape)\n",
        "\n",
        "    patchID = 0\n",
        "    for i in range(patches.shape[0]):\n",
        "      for j in range(patches.shape[1]):\n",
        "        patch = patches[i][j][0]\n",
        "        #patch = resize(patch, (IMAGE_DIM, IMAGE_DIM))\n",
        "        patch = resize(patch, (CROPPED_DIM, CROPPED_DIM))\n",
        "        patch = np.swapaxes(patch, 0, 1)\n",
        "        # images[:,:,:,patchID] = patch\n",
        "        #debug_img (patch, \"OG patch looks like\"+ str(np.all(patch<256)))\n",
        "        \n",
        "        patch_flat = np.sum(patch, axis=2)\n",
        "        # print (pch.size, np.nonzero(pch-255)[0].size, int(0.2*pch.size))\n",
        "        if np.nonzero(patch_flat-765.0)[0].size > int(0.2*patch_flat.size):\n",
        "          out = caffe_net_forward(patch, net)\n",
        "          # print (out.shape)\n",
        "          if patchID == 0:\n",
        "            cnnFea = out.T\n",
        "          else:\n",
        "            cnnFea = np.concatenate((cnnFea, out.T), axis=1)\n",
        "          patchID += 1\n",
        "    indexImage += [imageID for _ in range(patchID)]\n",
        "    \n",
        "    # print (cnnFea.shape, len(indexImage))\n",
        "    if imageID == 0:\n",
        "      label_cnnFea = cnnFea\n",
        "    else:\n",
        "      label_cnnFea = np.concatenate((label_cnnFea, cnnFea), axis=1)\n",
        "  with open(conf_imageDict, 'wb') as f:\n",
        "    print(\"Writing new image Dict file\")\n",
        "    pickle.dump(image_dict, f)\n",
        "  with open(conf_indexImg, 'wb') as f:\n",
        "    print (\"Writing new index Img file\")\n",
        "    pickle.dump(indexImage, f)\n",
        "  with open(conf_cnnFeatures, 'wb') as f:\n",
        "    print (\"Writing npy file\")\n",
        "    np.save(f, label_cnnFea)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTe82gjvW0QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_images (im_path, patchSize):\n",
        "  I = plt.imread(im_path)\n",
        "  if I.dtype == np.uint8:\n",
        "    I = I.astype('<f')\n",
        "  # print (np.mean(I, (0,1)))\n",
        "  imHeight, imWidth, imDepth = I.shape\n",
        "  if imHeight > imWidth:\n",
        "    new_ht = int((256/float(imWidth))*imHeight)\n",
        "    I = resize(I, (new_ht, 256))\n",
        "  else:\n",
        "    new_width = int((256/float(imHeight)) * imWidth)\n",
        "    I = resize(I, (256, new_width))\n",
        "  \n",
        "  patches = view_as_windows(I, (patchSize, patchSize,3), step=conf_stepSize)\n",
        "  # print (patches.shape)\n",
        "  return patches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGx3_ZYiCF76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def debug_img (img, txt=\"\", rgb=True):\n",
        "  print (txt)\n",
        "  if rgb:\n",
        "    if np.all (img<256):\n",
        "      plt.imshow(img/256)\n",
        "    else:\n",
        "      plt.imshow(img)\n",
        "  else:\n",
        "    temp = img[:,:,0]\n",
        "    img[:,:,0] = img[:,:,2]\n",
        "    img[:,:,2] = temp\n",
        "    plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPoVvxrtcPBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Main loop for extracting CNN features and mining patterns\n",
        "\n",
        "for i in range(1,conf_numClasses+1):\n",
        "  print ('Extracting cnn features from class', i)\n",
        "  cnnFeaExtraction(i, conf_patchSize)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnyFM7VzsIq",
        "colab_type": "text"
      },
      "source": [
        "Sample Code to extract features from a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9uEVv71zryd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdb5bbcb-f41f-4c3e-af1e-a6d905e2edc8"
      },
      "source": [
        "im_path = \"/content/drive/My Drive/MDPM/data/shoes/image/127811_zappos_20181018_9124097_image0000.jpg\"\n",
        " \n",
        "net = setup_caffe()\n",
        "patches = sample_images(im_path, conf_patchSize)\n",
        "\n",
        "patchID = 0\n",
        "for i in range(patches.shape[0]):\n",
        "  for j in range(patches.shape[1]):\n",
        "    patch = patches[i][j][0]\n",
        "    patch = resize(patch, (CROPPED_DIM, CROPPED_DIM))\n",
        "    patch = np.swapaxes(patch, 0, 1)\n",
        "    \n",
        "    patch_flat = np.sum(patch, axis=2)\n",
        "    # print (pch.size, np.nonzero(pch-255)[0].size, int(0.2*pch.size))\n",
        "    if np.nonzero(patch_flat-765.0)[0].size > int(0.2*patch_flat.size):\n",
        "      out = caffe_net_forward(patch, net)\n",
        "      # print (out.shape)\n",
        "      if patchID == 0:\n",
        "        cnnFea = out.T\n",
        "      else:\n",
        "        cnnFea = np.concatenate((cnnFea, out.T), axis=1)\n",
        "      patchID += 1\n",
        "\n",
        "# print (cnnFea.shape, len(indexImage))\n",
        "label_cnnFea = cnnFea\n",
        "\n",
        "with open(conf_cnnFeatures, 'wb') as f:\n",
        "  print (\"Writing npy file\")\n",
        "  np.save(f, label_cnnFea)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing npy file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Jx2oYpWYb5",
        "colab_type": "text"
      },
      "source": [
        "Sample code to save patches as a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adt98P24ha8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8a5da4d7-62ec-4bcb-8185-e900e63653a7"
      },
      "source": [
        "def save_patches (classId, patch_size):\n",
        "  label = labels[classId-1]  \n",
        "  for imageID, im_path in enumerate(label.iterdir()):\n",
        "    patches = sample_images(im_path, patch_size)\n",
        "    patchId = 1\n",
        "    for i in range(patches.shape[0]):\n",
        "        for j in range(patches.shape[1]):\n",
        "          patch = patches[i][j][0]\n",
        "          with open ('/content/drive/My Drive/MDPM/patches/'+ str(imageID+1) + \"_\" + str(patchId)+'.npy', 'wb') as f:\n",
        "            np.save(f, patch)\n",
        "          patchId += 1\n",
        "  \n",
        "save_patches(1, conf_patchSizeL3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[161.15436 161.12009 168.11465]\n",
            "[159.84453 171.8712  207.5988 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NteI6fd4xjy6",
        "colab_type": "text"
      },
      "source": [
        "Code to get dataset mean for the shoes images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Ggp8FYVqYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "441d1e8b-3891-420d-f9ac-b83979a42e8c"
      },
      "source": [
        "def get_dataset_mean(classId, patchSize):\n",
        "  label = labels[classId-1]  \n",
        "\n",
        "  sum_arr = np.zeros((3,))\n",
        "  pixel_num = 0\n",
        "  num_images = 0\n",
        "  \n",
        "  for imageID, im_path in enumerate(label.iterdir()):\n",
        "    num_images += 1\n",
        "    patches = sample_images(im_path, patchSize)\n",
        "    for i in range(patches.shape[0]):\n",
        "        for j in range(patches.shape[1]):\n",
        "          patch = patches[i][j][0]\n",
        "          patch = patch/256\n",
        "          sum_arr[0] += np.sum(patch[:,:,0])         \n",
        "          sum_arr[1] += np.sum(patch[:,:,1])\n",
        "          sum_arr[2] += np.sum(patch[:,:,2])\n",
        "          pixel_num += np.size(patch[:,:,0])\n",
        "  print (\"Analyzed\", num_images, \"images\")\n",
        "  return (sum_arr/pixel_num)*256\n",
        "  \n",
        "IMAGE_MEAN = get_dataset_mean(1, conf_patchSize)\n",
        "print ('RGB IMAGE_MEAN is', IMAGE_MEAN)\n",
        "temp = IMAGE_MEAN[0]\n",
        "IMAGE_MEAN[0] = IMAGE_MEAN[2]\n",
        "IMAGE_MEAN[2] = temp\n",
        "print ('BGR IMAGE_MEAN is', IMAGE_MEAN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzed 130 images\n",
            "RGB IMAGE_MEAN is [169.37496185 158.50061805 158.12070422]\n",
            "BGR IMAGE_MEAN is [158.12070422 158.50061805 169.37496185]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKLe9IKIZvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5385d495-6560-4933-b7d8-b3b0110f2a39"
      },
      "source": [
        "IMAGE_MEAN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([158.12070422, 158.50061805, 169.37496185])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_aQzYUQIG0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(conf_image_mean, 'wb') as f:\n",
        "  np.save(f, IMAGE_MEAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSmSb2lwnVbE",
        "colab_type": "text"
      },
      "source": [
        "Code to load ilvsvrc mean (BGR format)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4JDpIO8hqD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ilsvrc_mean ():\n",
        "  mean_arr = np.load(ROOT + 'ilsvrc_2012_mean.npy')\n",
        "  assert (mean_arr.dtype == 'float64')\n",
        "  #mean_arr = np.swapaxes(mean_arr,0,2)\n",
        "  mean_arr = mean_arr.mean(1).mean(1)\n",
        "  #plt.imshow(mean_arr.mean(1).mean(1))\n",
        "  return mean_arr\n",
        "\n",
        "#IMAGE_MEAN = get_ilsvrc_mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcIVg_1MAZ9T",
        "colab_type": "text"
      },
      "source": [
        "Combine the cnnFeature files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtKaHXWAZsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# cnn1 = '/content/drive/My Drive/MDPM/output/shoes/cnnFeatures1.npy'\n",
        "# cnn2 = '/content/drive/My Drive/MDPM/output/shoes/cnnFeatures2.npy'\n",
        "# cnn3 = '/content/drive/My Drive/MDPM/output/shoes/cnnFeatures3.npy'\n",
        "# cnn4 = '/content/drive/My Drive/MDPM/output/shoes/cnnFeatures4.npy'\n",
        "cnn5 = './MDPM_python/cnnFeatures5.npy'\n",
        "# cnn12 = './MDPM_python/cnnFeatures12.npy'\n",
        "# cnn34 = './MDPM_python/cnnFeatures34.npy'\n",
        "cnn1234 = './MDPM_python/cnnFeatures1234.npy'\n",
        "cnn = './MDPM_python/cnnFeatures.npy'\n",
        "\n",
        "# cnnFeat1 = np.load(cnn1)\n",
        "# cnnFeat2 = np.load(cnn2)\n",
        "# cnnFeat3 = np.load(cnn3)\n",
        "# cnnFeat4 = np.load(cnn4)\n",
        "# cnnFeat5 = np.load(cnn5)\n",
        "\n",
        "cnnFeat5 = np.load(cnn5)\n",
        "# cnnFeat34 = np.load(cnn34)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0A5_MFFEw4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnnFeat = np.concatenate((cnnFeat1234,cnnFeat5), axis=1)\n",
        "np.save(cnn,cnnFeat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6qnwwuOCIe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert cnnFeat.shape[0] == cnnFeat1234.shape[0] == cnnFeat5.shape[0]# == cnnFeat3.shape[0] == cnnFeat4.shape[0] == cnnFeat5.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJdDxZzrFDD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert cnnFeat.shape[1] == (cnnFeat1234.shape[1] + cnnFeat5.shape[1] )#+ cnnFeat3.shape[1] + cnnFeat4.shape[1] + cnnFeat5.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o34n0UeUfUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert np.all(cnnFeat[:,0] == cnnFeat12[:,0])\n",
        "assert np.all(cnnFeat[:,205584] == cnnFeat5[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}